{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "from skimage.transform import resize\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from animate import normalize_kp\n",
    "from demo import load_checkpoints\n",
    "import numpy as np\n",
    "from IPython.display import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from skimage import img_as_ubyte\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from cv2 import VideoWriter, VideoWriter_fourcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "source_image = imageio.imread('Inputs/feynman.jpeg')\n",
    "source_image = resize(source_image,(256,256))[..., :3]\n",
    "generator, kp_detector = load_checkpoints(config_path='config/vox-256.yaml', checkpoint_path='checkpoints/vox-cpk.pth.tar')\n",
    "plt.imshow(source_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('output'):\n",
    "    os.mkdir('output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "relative=True\n",
    "adapt_movement_scale=True\n",
    "cpu=False\n",
    "# face_cascade = cv2.CascadeClassifier('cascades/data/haarcascade_frontalface_default.xml')\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "out1 = cv2.VideoWriter('output/test.avi', fourcc, 12, (256*3 , 256), True)\n",
    "\n",
    "cv2_source = cv2.cvtColor(source_image.astype('float32'),cv2.COLOR_BGR2RGB)\n",
    "with torch.no_grad() :\n",
    "    predictions = []\n",
    "    source = torch.tensor(source_image[np.newaxis].astype(np.float32)).permute(0, 3, 1, 2)\n",
    "    if not cpu:\n",
    "        source = source.cuda()\n",
    "    kp_source = kp_detector(source)\n",
    "    count = 0\n",
    "    while(True):\n",
    "        ims = [source_image]\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "#         out1.write(frame)\n",
    "        frame = cv2.flip(frame,1)\n",
    "        \n",
    "#         faces = face_cascade.detectMultiScale(frame, scaleFactor=1.5, minNeighbors=5)\n",
    "#         if len(faces) != 0:\n",
    "#             x,y,w,h = faces[0]\n",
    "#             x = x-70\n",
    "#             y = y-70\n",
    "#             w = w+140\n",
    "#             h = h+140\n",
    "#             print(x,y,w,h,faces[0])\n",
    "#         else:\n",
    "        x = 143\n",
    "        y = 87\n",
    "        w = 322\n",
    "        h = 322 \n",
    "\n",
    "        frame = frame[y:y+h,x:x+w]\n",
    "#         test = img_as_ubyte(frame)\n",
    "#         out1.write(test)\n",
    "        frame1 = resize(frame,(256,256))[..., :3]\n",
    "#         cv2.imwrite('output/test'+str(count)+'.jpg',img_as_ubyte(frame1))\n",
    "        if count == 0:\n",
    "            source_image1 = frame1\n",
    "            source1 = torch.tensor(source_image1[np.newaxis].astype(np.float32)).permute(0, 3, 1, 2)\n",
    "            kp_driving_initial = kp_detector(source1)\n",
    "        \n",
    "        frame_test = torch.tensor(frame1[np.newaxis].astype(np.float32)).permute(0, 3, 1, 2)\n",
    "\n",
    "        driving_frame = frame_test\n",
    "        if not cpu:\n",
    "            driving_frame = driving_frame.cuda()\n",
    "        kp_driving = kp_detector(driving_frame)\n",
    "        kp_norm = normalize_kp(kp_source=kp_source,\n",
    "                               kp_driving=kp_driving,\n",
    "                               kp_driving_initial=kp_driving_initial, \n",
    "                               use_relative_movement=relative,\n",
    "                               use_relative_jacobian=relative, \n",
    "                               adapt_movement_scale=adapt_movement_scale)\n",
    "        out = generator(source, kp_source=kp_source, kp_driving=kp_norm)\n",
    "        predictions.append(np.transpose(out['prediction'].data.cpu().numpy(), [0, 2, 3, 1])[0])\n",
    "        im = np.transpose(out['prediction'].data.cpu().numpy(), [0, 2, 3, 1])[0]\n",
    "        im = cv2.cvtColor(im,cv2.COLOR_RGB2BGR)\n",
    "        joinedFrame = np.concatenate((cv2_source,im,frame1),axis=1)\n",
    "        \n",
    "        cv2.imshow('Test',joinedFrame)\n",
    "        out1.write(img_as_ubyte(joinedFrame))\n",
    "        count += 1\n",
    "        if cv2.waitKey(20) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "    cap.release()\n",
    "    out1.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
